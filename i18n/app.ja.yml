ja:
  application_name: "Transcriber"
  date_format: "%Y年%m月%d日"
  text_table_header_time: "時刻"
  text_table_header_summary: "要点・アクションアイテム"
  text_table_header_conversation: "会話(校正済み)"
  text_error_in_qualifying: "分析中にエラーが発生しました"
  text_action_item: "AI:"
  text_language_detected: "入力言語を%(new_language)sに切り替えました (変更前: %(old_language)s)"
  tab_current: "記録中"
  tab_history: "履歴"
  tab_diarization: "話者識別"
  tab_configuration: "設定"
  history_date: "記録日"
  history_reload: "再読み込み"
  diarization_update: "最新の情報に更新"
  diarization_update_with_plot: "クラスタリング結果を可視化する(少し時間がかかります)"
  diarization_person_selector: "人物を選択"
  diarization_new_name: "変更後の名前"
  diarization_person_rename: "名前を変更"
  diarization_person_erase: "削除"
  diarization_table_person_id: "話者ID"
  diarization_table_superseded_by: "統合先"
  diarization_table_name: "名前"
  diarization_table_last_mapped_time: "最後に認識された日時"
  diarization_table_not_mapped: "特徴量ベクトル一致なし"
  conf_apply_desc: "設定を適用する際に認識器が再起動します。再起動のため短時間記録が停止します。"
  conf_apply: "設定を適用"
  conf_enable_plugins: "プラグインを有効にする(適用にはアプリケーションの再起動が必要)"
  conf_input_language: "入力音声の言語"
  conf_enable_auto_detect_language: "入力音声の言語を自動で推定する"
  conf_enable_simultaneous_interpretation: "入力言語と出力言語が異なる場合、リアルタイム翻訳を有効にする"
  conf_output_language: "出力する言語"
  conf_ui_language: "UI言語(適用にはアプリケーションの再起動が必要)"
  conf_ui_show_input_status: "入力音声の計測結果を表示"
  conf_ui_show_statement_properties: "会話文に認識時の計測結果を表示"
  conf_input_devices: "入力デバイス: 何も選んでいない場合は自動選択"
  conf_device: "認識処理を実行するデバイス(通信経由の場合は \"アドレス:ポート\" を指定)"
  conf_vad_group: "VAD(有音検出)の設定"
  conf_vad_threshold: "VAD閾値"
  conf_vad_pre_hold: "VAD pre-hold [s]"
  conf_vad_post_hold: "VAD post-hold [s]"
  conf_vad_post_apply: "VAD post-apply [s]"
  conf_vad_soft_limit_length: "VAD soft limit [s]"
  conf_vad_hard_limit_length: "VAD hard limit [s]"
  conf_vad_wakeup_peak_threshold_db: "VADを開始するピークレベル [dB]"
  conf_vad_wakeup_release: "ピークレベルが指定を下回った後VADを停止するまでの時間 [s]"
  conf_embedding_type: "話者特徴量ベクトルの計算アルゴリズム(GPUの場合はpyannoteを推奨)"
  conf_embedding_type_none: "使用しない"
  conf_emb_group: "話者特徴量ベクトル計算の設定"
  conf_transcribe_min_duration: "VADで検出する発話区間の最小長 [s]"
  conf_transcribe_min_segment_duration: "発話の最小長 [s]"
  conf_keep_audio_file: "音声を保存する"
  conf_keep_audio_file_for: "音声の保存期間 [days]"
  conf_emb_sb_group: "話者特徴量ベクトル計算の詳細設定(speechbrain)"
  conf_emb_pn_group: "話者特徴量ベクトル計算の詳細設定(pyannote)"
  conf_emb_threshold: "同一話者とみなす特徴量ベクトルの最大距離"
  conf_emb_dbscan_eps: "片方の特徴量ベクトルがもう片方の特徴量ベクトルの近傍にあるとみなされるための、2つの特徴量ベクトル間の最大距離"
  conf_emb_dbscan_min_samples: "ある点をコア点とみなすための近傍点の特徴量ベクトル数"
  conf_emb_min_matched_embeddings_to_inherit_cluster: "クラスタリング世代間でクラスタを引き継ぐために合致する必要のある話者特徴量ベクトルの数"
  conf_emb_min_matched_embeddings_to_match_person: "登録された話者とクラスタを再結合するために合致する必要のある話者特徴量ベクトルの数"
  conf_max_hold_embeddings: "1話者あたり保持する特徴量ベクトルの最大数"
  conf_openai_api_key: "OpenAI API Key (適用にはアプリケーションの再起動が必要)"
  conf_qualify_group: "要約作成の設定"
  conf_qualify_soft_limit: "文章グループの最大長(soft limit) [s]"
  conf_qualify_hard_limit: "文章グループの最大長(hard limit) [s]"
  conf_qualify_silent_interval: "文章グループを区切る無音区間の長さ [s]"
  conf_qualify_merge_interval: "同一話者の発話をまとめる際に許容される無音区間の長さ [s]"
  conf_qualify_merge_threshold: "同一話者の発話をまとめる際に許容される特徴量ベクトルの最大距離"
  conf_qualify_llm_model_name_step1: "LLMモデル(訂正用)"
  conf_qualify_llm_model_name_step2: "LLMモデル(要約生成用)"
  qualify_llm_authentication_error: "(通信または認証の問題により解析を中断しました)"
